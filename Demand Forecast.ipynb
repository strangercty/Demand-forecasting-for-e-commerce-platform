{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "# Imports several basic packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import time\n",
    "from scipy import stats\n",
    "import datetime as dt\n",
    "import gc\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore the warnings\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# import the package of heterogenous classifiers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/mac/Desktop/UCB/290-Data-X/Project/Dataset/summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_id</th>\n",
       "      <th>order_time</th>\n",
       "      <th>sales</th>\n",
       "      <th>sales_sum/2w</th>\n",
       "      <th>sales_sum/month</th>\n",
       "      <th>sales_sum/quarter</th>\n",
       "      <th>comment_sum</th>\n",
       "      <th>comment_mean</th>\n",
       "      <th>comment_mean/2w</th>\n",
       "      <th>comment_mean/month</th>\n",
       "      <th>...</th>\n",
       "      <th>area</th>\n",
       "      <th>area_sum/2w</th>\n",
       "      <th>area_sum/month</th>\n",
       "      <th>area_sum/quarter</th>\n",
       "      <th>price</th>\n",
       "      <th>cate</th>\n",
       "      <th>para_1</th>\n",
       "      <th>para_2</th>\n",
       "      <th>para_3</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10033</td>\n",
       "      <td>2016/5/1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1375.3</td>\n",
       "      <td>30</td>\n",
       "      <td>667.43</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10033</td>\n",
       "      <td>2016/5/15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1375.3</td>\n",
       "      <td>30</td>\n",
       "      <td>667.43</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10033</td>\n",
       "      <td>2016/5/29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1375.3</td>\n",
       "      <td>30</td>\n",
       "      <td>667.43</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10033</td>\n",
       "      <td>2016/6/12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1375.3</td>\n",
       "      <td>30</td>\n",
       "      <td>667.43</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10033</td>\n",
       "      <td>2016/6/26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1375.3</td>\n",
       "      <td>30</td>\n",
       "      <td>667.43</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73071</td>\n",
       "      <td>9981</td>\n",
       "      <td>2017/3/5</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>316.3</td>\n",
       "      <td>101</td>\n",
       "      <td>174.05</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73072</td>\n",
       "      <td>9981</td>\n",
       "      <td>2017/3/19</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>32</td>\n",
       "      <td>316.3</td>\n",
       "      <td>101</td>\n",
       "      <td>174.05</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73073</td>\n",
       "      <td>9981</td>\n",
       "      <td>2017/4/2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>40</td>\n",
       "      <td>316.3</td>\n",
       "      <td>101</td>\n",
       "      <td>174.05</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73074</td>\n",
       "      <td>9981</td>\n",
       "      <td>2017/4/16</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>42</td>\n",
       "      <td>316.3</td>\n",
       "      <td>101</td>\n",
       "      <td>174.05</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73075</td>\n",
       "      <td>9981</td>\n",
       "      <td>2017/4/30</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>47</td>\n",
       "      <td>316.3</td>\n",
       "      <td>101</td>\n",
       "      <td>174.05</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73076 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sku_id order_time  sales  sales_sum/2w  sales_sum/month  \\\n",
       "0       10033   2016/5/1      0             0                0   \n",
       "1       10033  2016/5/15      0             0                0   \n",
       "2       10033  2016/5/29      0             0                0   \n",
       "3       10033  2016/6/12      0             0                0   \n",
       "4       10033  2016/6/26      0             0                0   \n",
       "...       ...        ...    ...           ...              ...   \n",
       "73071    9981   2017/3/5      0            13               25   \n",
       "73072    9981  2017/3/19      0             4               18   \n",
       "73073    9981   2017/4/2      0             9               13   \n",
       "73074    9981  2017/4/16      0             5               14   \n",
       "73075    9981  2017/4/30      0            14               19   \n",
       "\n",
       "       sales_sum/quarter  comment_sum  comment_mean  comment_mean/2w  \\\n",
       "0                      0            0             0              0.0   \n",
       "1                      0            0             0              0.0   \n",
       "2                      0            0             0              0.0   \n",
       "3                      0            0             0              0.0   \n",
       "4                      0            0             0              0.0   \n",
       "...                  ...          ...           ...              ...   \n",
       "73071                 35            3             1              1.0   \n",
       "73072                 39            0             0              1.0   \n",
       "73073                 48            0             0              1.0   \n",
       "73074                 49            0             0              1.5   \n",
       "73075                 57            0             0              1.0   \n",
       "\n",
       "       comment_mean/month  ...  area  area_sum/2w  area_sum/month  \\\n",
       "0                     0.0  ...     0            0               0   \n",
       "1                     0.0  ...     0            0               0   \n",
       "2                     0.0  ...     0            0               0   \n",
       "3                     0.0  ...     0            0               0   \n",
       "4                     0.0  ...     0            0               0   \n",
       "...                   ...  ...   ...          ...             ...   \n",
       "73071                 1.0  ...     0           12              22   \n",
       "73072                 1.0  ...     0            4              17   \n",
       "73073                 1.0  ...     0            8              12   \n",
       "73074                 1.4  ...     0            4              12   \n",
       "73075                 1.4  ...     0            9              13   \n",
       "\n",
       "       area_sum/quarter   price  cate  para_1  para_2  para_3  output  \n",
       "0                     0  1375.3    30  667.43      -1      -1     0.0  \n",
       "1                     0  1375.3    30  667.43      -1      -1     0.0  \n",
       "2                     0  1375.3    30  667.43      -1      -1     0.0  \n",
       "3                     0  1375.3    30  667.43      -1      -1     0.0  \n",
       "4                     0  1375.3    30  667.43      -1      -1     0.0  \n",
       "...                 ...     ...   ...     ...     ...     ...     ...  \n",
       "73071                28   316.3   101  174.05       4       4    12.0  \n",
       "73072                32   316.3   101  174.05       4       4    13.0  \n",
       "73073                40   316.3   101  174.05       4       4     4.0  \n",
       "73074                42   316.3   101  174.05       4       4     9.0  \n",
       "73075                47   316.3   101  174.05       4       4     5.0  \n",
       "\n",
       "[73076 rows x 40 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2016/7/10', '2016/10/16', '2017/3/19', '2016/8/7', '2016/5/1', '2016/9/18', '2016/9/4', '2017/4/2', '2017/4/30', '2016/7/24', '2016/6/26', '2017/1/8', '2017/2/19', '2016/11/13', '2016/10/30', '2016/6/12', '2017/1/22', '2016/12/11', '2017/2/5', '2016/10/2', '2016/12/25', '2016/11/27', '2017/4/16', '2016/5/29', '2016/8/21', '2016/5/15', '2017/3/5'}\n"
     ]
    }
   ],
   "source": [
    "date = set(data['order_time'])\n",
    "print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 30, 46, 71, 83, 101}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data['cate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract numeric features from date\n",
    "order_time = data['order_time']\n",
    "order_time_df = pd.to_datetime(order_time) \n",
    "data['year_order_time'] = order_time_df.dt.year \n",
    "data['month_order_time'] = order_time_df.dt.month \n",
    "data['day_order_time'] = order_time_df.dt.day \n",
    "data['hour_order_time'] = order_time_df.dt.hour\n",
    "data['minute_order_time'] = order_time_df.dt.minute\n",
    "data['second_order_time'] = order_time_df.dt.second\n",
    "data['weekday_order_time'] = order_time_df.dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply One-Hot-Encoding to categorical features\n",
    "def One_hot_encoding(dataframe, features):\n",
    "    feature_dummy = []\n",
    "    for i in features:\n",
    "        dataframe_dummy = pd.get_dummies(dataframe[i], prefix = i)\n",
    "        feature_dummy.append(dataframe_dummy)\n",
    "    dataframe_new = pd.concat(feature_dummy + [dataframe], axis = 1)\n",
    "    dataframe_new.drop(features, inplace = True, axis = 1)\n",
    "    return dataframe_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sku_id', 'order_time', 'sales', 'sales_sum/2w', 'sales_sum/month',\n",
       "       'sales_sum/quarter', 'comment_sum', 'comment_mean', 'comment_mean/2w',\n",
       "       'comment_mean/month', 'comment_mean/quarter', 'comment_sum/2w',\n",
       "       'comment_sum/month', 'comment_sum/quarter', 'browse', 'follow',\n",
       "       'browse/2w', 'browse/month', 'browse/quarter', 'follow/2w',\n",
       "       'follow/month', 'follow/quarter', 'user_lv', 'user_num', 'user_lv/2w',\n",
       "       'user_lv/month', 'user_lv/quarter', 'user_num/2w', 'user_num/month',\n",
       "       'user_num/quarter', 'area', 'area_sum/2w', 'area_sum/month',\n",
       "       'area_sum/quarter', 'price', 'cate', 'para_1', 'para_2', 'para_3',\n",
       "       'output', 'year_order_time', 'month_order_time', 'day_order_time',\n",
       "       'hour_order_time', 'minute_order_time', 'second_order_time',\n",
       "       'weekday_order_time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply one-hot encoding\n",
    "feature_cols = ['cate', 'year_order_time', 'month_order_time']\n",
    "data_oh = One_hot_encoding(data, feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = data_oh[data_oh['order_time'] != '2017/4/30']\n",
    "training_set = training_set[training_set['order_time'] != '2017/4/16']\n",
    "training_set = training_set[training_set['order_time'] != '2016/5/1']\n",
    "training_set = training_set[training_set['order_time'] != '2016/10/30']\n",
    "testing_set = data_oh[data_oh['order_time'] == '2017/4/16']\n",
    "training_set.reset_index(inplace = True)\n",
    "testing_set.reset_index(inplace = True)\n",
    "del training_set['index']\n",
    "del testing_set['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2016/10/16',\n",
       " '2016/10/2',\n",
       " '2016/10/30',\n",
       " '2016/11/13',\n",
       " '2016/12/11',\n",
       " '2016/12/25',\n",
       " '2016/5/15',\n",
       " '2016/5/29',\n",
       " '2016/6/12',\n",
       " '2016/6/26',\n",
       " '2016/7/10',\n",
       " '2016/7/24',\n",
       " '2016/8/21',\n",
       " '2016/8/7',\n",
       " '2016/9/18',\n",
       " '2016/9/4',\n",
       " '2017/1/22',\n",
       " '2017/1/8',\n",
       " '2017/2/19',\n",
       " '2017/2/5',\n",
       " '2017/3/19',\n",
       " '2017/3/5',\n",
       " '2017/4/2'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(training_set['order_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2017/4/16'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(testing_set['order_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.index = training_set['sku_id']\n",
    "testing_set.index = testing_set['sku_id']\n",
    "drop_columns = ['sku_id', 'order_time']\n",
    "training_set.drop(drop_columns, inplace = True, axis = 1)\n",
    "testing_set.drop(drop_columns, inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.to_csv('/Users/mac/Desktop/UCB/290-Data-X/Project/Dataset/train.csv')\n",
    "testing_set.to_csv('/Users/mac/Desktop/UCB/290-Data-X/Project/Dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv('/Users/mac/Desktop/UCB/290-Data-X/Project/Dataset/train.csv', index_col = 'sku_id')  \n",
    "testing_set = pd.read_csv('/Users/mac/Desktop/UCB/290-Data-X/Project/Dataset/test.csv', index_col = 'sku_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sku_id = list(set(training_set.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16385,\n",
       " 98308,\n",
       " 32774,\n",
       " 49159,\n",
       " 90120,\n",
       " 49162,\n",
       " 49163,\n",
       " 24592,\n",
       " 73744,\n",
       " 81939,\n",
       " 32790,\n",
       " 73753,\n",
       " 16410,\n",
       " 24603,\n",
       " 24605,\n",
       " 73759,\n",
       " 49188,\n",
       " 57385,\n",
       " 73769,\n",
       " 43,\n",
       " 81964,\n",
       " 57391,\n",
       " 73776,\n",
       " 98359,\n",
       " 49210,\n",
       " 8253,\n",
       " 98369,\n",
       " 49218,\n",
       " 8259,\n",
       " 49223,\n",
       " 98375,\n",
       " 49226,\n",
       " 76,\n",
       " 57422,\n",
       " 32848,\n",
       " 90202,\n",
       " 32860,\n",
       " 82014,\n",
       " 16479,\n",
       " 98,\n",
       " 32867,\n",
       " 41061,\n",
       " 82022,\n",
       " 90217,\n",
       " 32876,\n",
       " 57452,\n",
       " 73838,\n",
       " 8302,\n",
       " 73844,\n",
       " 32885,\n",
       " 73845,\n",
       " 16503,\n",
       " 24697,\n",
       " 16513,\n",
       " 132,\n",
       " 32901,\n",
       " 73861,\n",
       " 82055,\n",
       " 65672,\n",
       " 8328,\n",
       " 49302,\n",
       " 16536,\n",
       " 65690,\n",
       " 8349,\n",
       " 90269,\n",
       " 73894,\n",
       " 32936,\n",
       " 98472,\n",
       " 82091,\n",
       " 65708,\n",
       " 24753,\n",
       " 90291,\n",
       " 57527,\n",
       " 32952,\n",
       " 73913,\n",
       " 98494,\n",
       " 57537,\n",
       " 41155,\n",
       " 90307,\n",
       " 57541,\n",
       " 16582,\n",
       " 16586,\n",
       " 24778,\n",
       " 32973,\n",
       " 41165,\n",
       " 98512,\n",
       " 209,\n",
       " 16596,\n",
       " 57557,\n",
       " 73943,\n",
       " 32986,\n",
       " 219,\n",
       " 57562,\n",
       " 16607,\n",
       " 65760,\n",
       " 90335,\n",
       " 98527,\n",
       " 32995,\n",
       " 82148,\n",
       " 41189,\n",
       " 41190,\n",
       " 57574,\n",
       " 8419,\n",
       " 41193,\n",
       " 49390,\n",
       " 239,\n",
       " 41200,\n",
       " 41201,\n",
       " 49393,\n",
       " 49399,\n",
       " 16633,\n",
       " 24825,\n",
       " 49403,\n",
       " 65788,\n",
       " 254,\n",
       " 49409,\n",
       " 260,\n",
       " 8459,\n",
       " 57617,\n",
       " 24851,\n",
       " 74010,\n",
       " 82208,\n",
       " 33059,\n",
       " 74020,\n",
       " 16677,\n",
       " 57638,\n",
       " 65831,\n",
       " 33064,\n",
       " 82214,\n",
       " 57646,\n",
       " 82222,\n",
       " 98609,\n",
       " 65851,\n",
       " 24892,\n",
       " 16704,\n",
       " 98624,\n",
       " 74052,\n",
       " 8516,\n",
       " 16710,\n",
       " 24903,\n",
       " 33097,\n",
       " 49482,\n",
       " 49483,\n",
       " 16716,\n",
       " 82251,\n",
       " 98634,\n",
       " 16719,\n",
       " 342,\n",
       " 90454,\n",
       " 347,\n",
       " 24924,\n",
       " 41307,\n",
       " 8541,\n",
       " 90461,\n",
       " 74080,\n",
       " 8552,\n",
       " 98667,\n",
       " 8556,\n",
       " 57709,\n",
       " 65902,\n",
       " 57711,\n",
       " 98672,\n",
       " 24946,\n",
       " 57714,\n",
       " 24948,\n",
       " 8564,\n",
       " 41335,\n",
       " 65912,\n",
       " 57723,\n",
       " 380,\n",
       " 16767,\n",
       " 98688,\n",
       " 74114,\n",
       " 98692,\n",
       " 33158,\n",
       " 24967,\n",
       " 24968,\n",
       " 57735,\n",
       " 65926,\n",
       " 90510,\n",
       " 98709,\n",
       " 74134,\n",
       " 90524,\n",
       " 24990,\n",
       " 24991,\n",
       " 49570,\n",
       " 65956,\n",
       " 24997,\n",
       " 98730,\n",
       " 74157,\n",
       " 33201,\n",
       " 98739,\n",
       " 90549,\n",
       " 49591,\n",
       " 25016,\n",
       " 41401,\n",
       " 8632,\n",
       " 98749,\n",
       " 16830,\n",
       " 25024,\n",
       " 41412,\n",
       " 25030,\n",
       " 33223,\n",
       " 41419,\n",
       " 98764,\n",
       " 33229,\n",
       " 41421,\n",
       " 65997,\n",
       " 41425,\n",
       " 98769,\n",
       " 33236,\n",
       " 468,\n",
       " 33244,\n",
       " 16862,\n",
       " 49633,\n",
       " 25060,\n",
       " 49638,\n",
       " 66025,\n",
       " 41457,\n",
       " 74225,\n",
       " 90609,\n",
       " 25077,\n",
       " 33271,\n",
       " 504,\n",
       " 98815,\n",
       " 74240,\n",
       " 74245,\n",
       " 82437,\n",
       " 90629,\n",
       " 49675,\n",
       " 49677,\n",
       " 25105,\n",
       " 25107,\n",
       " 25110,\n",
       " 57881,\n",
       " 98850,\n",
       " 41508,\n",
       " 49703,\n",
       " 90663,\n",
       " 98858,\n",
       " 41518,\n",
       " 49710,\n",
       " 49712,\n",
       " 82479,\n",
       " 90673,\n",
       " 41523,\n",
       " 16949,\n",
       " 41526,\n",
       " 49718,\n",
       " 66102,\n",
       " 98873,\n",
       " 82501,\n",
       " 16979,\n",
       " 49748,\n",
       " 600,\n",
       " 57952,\n",
       " 90720,\n",
       " 41570,\n",
       " 25188,\n",
       " 25189,\n",
       " 613,\n",
       " 614,\n",
       " 74351,\n",
       " 625,\n",
       " 57971,\n",
       " 74357,\n",
       " 17018,\n",
       " 634,\n",
       " 41596,\n",
       " 74365,\n",
       " 33406,\n",
       " 74371,\n",
       " 8835,\n",
       " 17032,\n",
       " 82568,\n",
       " 25227,\n",
       " 41611,\n",
       " 41613,\n",
       " 654,\n",
       " 98959,\n",
       " 41617,\n",
       " 657,\n",
       " 658,\n",
       " 74385,\n",
       " 82577,\n",
       " 74396,\n",
       " 673,\n",
       " 8870,\n",
       " 41639,\n",
       " 98982,\n",
       " 41641,\n",
       " 98987,\n",
       " 58028,\n",
       " 25262,\n",
       " 58032,\n",
       " 98994,\n",
       " 8883,\n",
       " 25279,\n",
       " 8897,\n",
       " 707,\n",
       " 74435,\n",
       " 49867,\n",
       " 90827,\n",
       " 8920,\n",
       " 90843,\n",
       " 49884,\n",
       " 25310,\n",
       " 41695,\n",
       " 41696,\n",
       " 82657,\n",
       " 99046,\n",
       " 25319,\n",
       " 41706,\n",
       " 33519,\n",
       " 58096,\n",
       " 17141,\n",
       " 33531,\n",
       " 66299,\n",
       " 17149,\n",
       " 25344,\n",
       " 41730,\n",
       " 772,\n",
       " 8965,\n",
       " 90891,\n",
       " 8973,\n",
       " 82702,\n",
       " 58127,\n",
       " 58128,\n",
       " 17171,\n",
       " 74516,\n",
       " 788,\n",
       " 82707,\n",
       " 17184,\n",
       " 800,\n",
       " 99105,\n",
       " 33577,\n",
       " 82731,\n",
       " 66349,\n",
       " 66361,\n",
       " 826,\n",
       " 49979,\n",
       " 25406,\n",
       " 74559,\n",
       " 33605,\n",
       " 33609,\n",
       " 90954,\n",
       " 90957,\n",
       " 9039,\n",
       " 41809,\n",
       " 41813,\n",
       " 58197,\n",
       " 25435,\n",
       " 33632,\n",
       " 41825,\n",
       " 33635,\n",
       " 90980,\n",
       " 875,\n",
       " 877,\n",
       " 17265,\n",
       " 41842,\n",
       " 74610,\n",
       " 90995,\n",
       " 58231,\n",
       " 41851,\n",
       " 25469,\n",
       " 66435,\n",
       " 50055,\n",
       " 91026,\n",
       " 91034,\n",
       " 50077,\n",
       " 82851,\n",
       " 91046,\n",
       " 82859,\n",
       " 82863,\n",
       " 58293,\n",
       " 82869,\n",
       " 58295,\n",
       " 66487,\n",
       " 91062,\n",
       " 91069,\n",
       " 17345,\n",
       " 66497,\n",
       " 25543,\n",
       " 25548,\n",
       " 25552,\n",
       " 82897,\n",
       " 981,\n",
       " 82903,\n",
       " 985,\n",
       " 74714,\n",
       " 74722,\n",
       " 33764,\n",
       " 17383,\n",
       " 17391,\n",
       " 58353,\n",
       " 74742,\n",
       " 58359,\n",
       " 33784,\n",
       " 66556,\n",
       " 99328,\n",
       " 1028,\n",
       " 1033,\n",
       " 1034,\n",
       " 82953,\n",
       " 17421,\n",
       " 1040,\n",
       " 42001,\n",
       " 17428,\n",
       " 74778,\n",
       " 58406,\n",
       " 33832,\n",
       " 74798,\n",
       " 42033,\n",
       " 82994,\n",
       " 91187,\n",
       " 58422,\n",
       " 83000,\n",
       " 83004,\n",
       " 74813,\n",
       " 9281,\n",
       " 91212,\n",
       " 17486,\n",
       " 33870,\n",
       " 91216,\n",
       " 58453,\n",
       " 42084,\n",
       " 83045,\n",
       " 66663,\n",
       " 83047,\n",
       " 1132,\n",
       " 66670,\n",
       " 1137,\n",
       " 33908,\n",
       " 91252,\n",
       " 33912,\n",
       " 83065,\n",
       " 66685,\n",
       " 1151,\n",
       " 17535,\n",
       " 74881,\n",
       " 33922,\n",
       " 66690,\n",
       " 91268,\n",
       " 9350,\n",
       " 91271,\n",
       " 74894,\n",
       " 83086,\n",
       " 83088,\n",
       " 74901,\n",
       " 91286,\n",
       " 33948,\n",
       " 42142,\n",
       " 1184,\n",
       " 1190,\n",
       " 9384,\n",
       " 74922,\n",
       " 33964,\n",
       " 25775,\n",
       " 58544,\n",
       " 91313,\n",
       " 58549,\n",
       " 58553,\n",
       " 42173,\n",
       " 83136,\n",
       " 1221,\n",
       " 33994,\n",
       " 33998,\n",
       " 1234,\n",
       " 74963,\n",
       " 17620,\n",
       " 25812,\n",
       " 17622,\n",
       " 1240,\n",
       " 34011,\n",
       " 50395,\n",
       " 58590,\n",
       " 17634,\n",
       " 91362,\n",
       " 74980,\n",
       " 9446,\n",
       " 34025,\n",
       " 66794,\n",
       " 9452,\n",
       " 66802,\n",
       " 1267,\n",
       " 17653,\n",
       " 83190,\n",
       " 58619,\n",
       " 17660,\n",
       " 83195,\n",
       " 17666,\n",
       " 66819,\n",
       " 25860,\n",
       " 42245,\n",
       " 66822,\n",
       " 58631,\n",
       " 25865,\n",
       " 75027,\n",
       " 75031,\n",
       " 66848,\n",
       " 42273,\n",
       " 25891,\n",
       " 34084,\n",
       " 83235,\n",
       " 58663,\n",
       " 83240,\n",
       " 1321,\n",
       " 17705,\n",
       " 50483,\n",
       " 17716,\n",
       " 1333,\n",
       " 34101,\n",
       " 25911,\n",
       " 75060,\n",
       " 42297,\n",
       " 91444,\n",
       " 91451,\n",
       " 50492,\n",
       " 1341,\n",
       " 58690,\n",
       " 34115,\n",
       " 17735,\n",
       " 34120,\n",
       " 58697,\n",
       " 83278,\n",
       " 9557,\n",
       " 1367,\n",
       " 34136,\n",
       " 1370,\n",
       " 9563,\n",
       " 50524,\n",
       " 58716,\n",
       " 83294,\n",
       " 34147,\n",
       " 42339,\n",
       " 75109,\n",
       " 50534,\n",
       " 1383,\n",
       " 91491,\n",
       " 1385,\n",
       " 34154,\n",
       " 34156,\n",
       " 58736,\n",
       " 34161,\n",
       " 66931,\n",
       " 9589,\n",
       " 25978,\n",
       " 17788,\n",
       " 34173,\n",
       " 17791,\n",
       " 9599,\n",
       " 58754,\n",
       " 42372,\n",
       " 50565,\n",
       " 9607,\n",
       " 66954,\n",
       " 75147,\n",
       " 17804,\n",
       " 9618,\n",
       " 50579,\n",
       " 91539,\n",
       " 91541,\n",
       " 83352,\n",
       " 1433,\n",
       " 83356,\n",
       " 83360,\n",
       " 50594,\n",
       " 50598,\n",
       " 42414,\n",
       " 9649,\n",
       " 1458,\n",
       " 34226,\n",
       " 50611,\n",
       " 91572,\n",
       " 1462,\n",
       " 42423,\n",
       " 26040,\n",
       " 50614,\n",
       " 67000,\n",
       " 75190,\n",
       " 67004,\n",
       " 83387,\n",
       " 50626,\n",
       " 17859,\n",
       " 17861,\n",
       " 42438,\n",
       " 50629,\n",
       " 91596,\n",
       " 34255,\n",
       " 9679,\n",
       " 17875,\n",
       " 67030,\n",
       " 34263,\n",
       " 75224,\n",
       " 83415,\n",
       " 91608,\n",
       " 26082,\n",
       " 17894,\n",
       " 42470,\n",
       " 9709,\n",
       " 17902,\n",
       " 91630,\n",
       " 75248,\n",
       " 67057,\n",
       " 9715,\n",
       " 9718,\n",
       " 58876,\n",
       " 67069,\n",
       " 17919,\n",
       " 42501,\n",
       " 9735,\n",
       " 67088,\n",
       " 34327,\n",
       " 50719,\n",
       " 17953,\n",
       " 42529,\n",
       " 42534,\n",
       " 50727,\n",
       " 17965,\n",
       " 67123,\n",
       " 75315,\n",
       " 50741,\n",
       " 83507,\n",
       " 91700,\n",
       " 1592,\n",
       " 91706,\n",
       " 1595,\n",
       " 42555,\n",
       " 91709,\n",
       " 75326,\n",
       " 50751,\n",
       " 91712,\n",
       " 75329,\n",
       " 9788,\n",
       " 9801,\n",
       " 17994,\n",
       " 75339,\n",
       " 67148,\n",
       " 91726,\n",
       " 75343,\n",
       " 18004,\n",
       " 67156,\n",
       " 58967,\n",
       " 18008,\n",
       " 67161,\n",
       " 26207,\n",
       " 42591,\n",
       " 34404,\n",
       " 67172,\n",
       " 9833,\n",
       " 91754,\n",
       " 91755,\n",
       " 67183,\n",
       " 75375,\n",
       " 83571,\n",
       " 50806,\n",
       " 91770,\n",
       " 75387,\n",
       " 42620,\n",
       " 42635,\n",
       " 83601,\n",
       " 26259,\n",
       " 9882,\n",
       " 75421,\n",
       " 75422,\n",
       " 9887,\n",
       " 50859,\n",
       " 91820,\n",
       " 91821,\n",
       " 75445,\n",
       " 9915,\n",
       " 59069,\n",
       " 18114,\n",
       " 59076,\n",
       " 91844,\n",
       " 1741,\n",
       " 26318,\n",
       " 1749,\n",
       " 9943,\n",
       " 1754,\n",
       " 50906,\n",
       " 59098,\n",
       " 9946,\n",
       " 75492,\n",
       " 18149,\n",
       " 83688,\n",
       " 67305,\n",
       " 83691,\n",
       " 1774,\n",
       " 1775,\n",
       " 34543,\n",
       " 75510,\n",
       " 50935,\n",
       " 9975,\n",
       " 67325,\n",
       " 91901,\n",
       " 1791,\n",
       " 9981,\n",
       " 67334,\n",
       " 18184,\n",
       " 67336,\n",
       " 83723,\n",
       " 26383,\n",
       " 75535,\n",
       " 34578,\n",
       " 18198,\n",
       " 75542,\n",
       " 1818,\n",
       " 50971,\n",
       " 18205,\n",
       " 50979,\n",
       " 1831,\n",
       " 26407,\n",
       " 18217,\n",
       " 50989,\n",
       " 83757,\n",
       " 75568,\n",
       " 10033,\n",
       " 34612,\n",
       " 42805,\n",
       " 1847,\n",
       " 75579,\n",
       " 67390,\n",
       " 10055,\n",
       " 26439,\n",
       " 26442,\n",
       " 26443,\n",
       " 91983,\n",
       " 26453,\n",
       " 42849,\n",
       " 75618,\n",
       " 75620,\n",
       " 1893,\n",
       " 59241,\n",
       " 51051,\n",
       " 75628,\n",
       " 83820,\n",
       " 83822,\n",
       " 92013,\n",
       " 26486,\n",
       " 1911,\n",
       " 42872,\n",
       " 26498,\n",
       " 92035,\n",
       " 34693,\n",
       " 83846,\n",
       " 42888,\n",
       " 26505,\n",
       " 1930,\n",
       " 34701,\n",
       " 59278,\n",
       " 1935,\n",
       " 83859,\n",
       " 34710,\n",
       " 59290,\n",
       " 42918,\n",
       " 10153,\n",
       " 92082,\n",
       " 51124,\n",
       " 51126,\n",
       " 10168,\n",
       " 42945,\n",
       " 75718,\n",
       " 26570,\n",
       " 59339,\n",
       " 83914,\n",
       " 10196,\n",
       " 75741,\n",
       " 67553,\n",
       " 59362,\n",
       " 92129,\n",
       " 2022,\n",
       " 18409,\n",
       " 10220,\n",
       " 51185,\n",
       " 10226,\n",
       " 2034,\n",
       " 34804,\n",
       " 59378,\n",
       " 42998,\n",
       " 83955,\n",
       " 10237,\n",
       " 18431,\n",
       " 43014,\n",
       " 34829,\n",
       " 67597,\n",
       " 26640,\n",
       " 92177,\n",
       " 18451,\n",
       " 83987,\n",
       " 43030,\n",
       " 75802,\n",
       " 18462,\n",
       " 92191,\n",
       " 18464,\n",
       " 59429,\n",
       " 10281,\n",
       " 51241,\n",
       " 43051,\n",
       " 34860,\n",
       " 59434,\n",
       " 59436,\n",
       " 84011,\n",
       " 18482,\n",
       " 26675,\n",
       " 67634,\n",
       " 34869,\n",
       " 51254,\n",
       " 84022,\n",
       " 34872,\n",
       " 2105,\n",
       " 67643,\n",
       " 18495,\n",
       " 75844,\n",
       " 18501,\n",
       " 43078,\n",
       " 67653,\n",
       " 43081,\n",
       " 92237,\n",
       " 2127,\n",
       " 34896,\n",
       " 43089,\n",
       " 34898,\n",
       " 51280,\n",
       " 67663,\n",
       " 75855,\n",
       " 10326,\n",
       " 75859,\n",
       " 84047,\n",
       " 34906,\n",
       " 34907,\n",
       " 10333,\n",
       " 34910,\n",
       " 92255,\n",
       " 34913,\n",
       " 10339,\n",
       " 67685,\n",
       " 2152,\n",
       " 84072,\n",
       " 92266,\n",
       " 10352,\n",
       " 67696,\n",
       " 43126,\n",
       " 34936,\n",
       " 59513,\n",
       " 84093,\n",
       " 75905,\n",
       " 84102,\n",
       " 84104,\n",
       " 92298,\n",
       " 51339,\n",
       " 2188,\n",
       " 51342,\n",
       " 43155,\n",
       " 2196,\n",
       " 51347,\n",
       " 18582,\n",
       " 26774,\n",
       " 2205,\n",
       " 75934,\n",
       " 18594,\n",
       " 43172,\n",
       " 43173,\n",
       " 18603,\n",
       " 2221,\n",
       " 10414,\n",
       " 75954,\n",
       " 67764,\n",
       " 43190,\n",
       " 10423,\n",
       " 35000,\n",
       " 18618,\n",
       " 26810,\n",
       " 51387,\n",
       " 2240,\n",
       " 84161,\n",
       " 67784,\n",
       " 2250,\n",
       " 51404,\n",
       " 59600,\n",
       " 84176,\n",
       " 10452,\n",
       " 2260,\n",
       " 51414,\n",
       " 51422,\n",
       " 2275,\n",
       " 35043,\n",
       " 10469,\n",
       " 84195,\n",
       " 2280,\n",
       " 35052,\n",
       " 18676,\n",
       " 18678,\n",
       " 59639,\n",
       " 43256,\n",
       " 51450,\n",
       " 92418,\n",
       " 35076,\n",
       " 10510,\n",
       " 59662,\n",
       " 67855,\n",
       " 76052,\n",
       " 51477,\n",
       " 51478,\n",
       " 18713,\n",
       " 43289,\n",
       " 43290,\n",
       " 18717,\n",
       " 35108,\n",
       " 35114,\n",
       " 67882,\n",
       " 59692,\n",
       " 76075,\n",
       " 92464,\n",
       " 43313,\n",
       " 51505,\n",
       " 43316,\n",
       " 2357,\n",
       " 92468,\n",
       " 51514,\n",
       " 67899,\n",
       " 92474,\n",
       " 18749,\n",
       " 67902,\n",
       " 18754,\n",
       " 2370,\n",
       " 92484,\n",
       " 51528,\n",
       " 67917,\n",
       " 2383,\n",
       " 18778,\n",
       " 35162,\n",
       " 10590,\n",
       " 43363,\n",
       " 84333,\n",
       " 51566,\n",
       " 43375,\n",
       " 84339,\n",
       " 43382,\n",
       " 18807,\n",
       " 67960,\n",
       " 10621,\n",
       " 43389,\n",
       " 67966,\n",
       " 43392,\n",
       " 10625,\n",
       " 43393,\n",
       " 92546,\n",
       " 43396,\n",
       " 2444,\n",
       " 59788,\n",
       " 76175,\n",
       " 18832,\n",
       " 51601,\n",
       " 51606,\n",
       " 59798,\n",
       " 2458,\n",
       " 2463,\n",
       " 76194,\n",
       " 18851,\n",
       " 76198,\n",
       " 84393,\n",
       " 35244,\n",
       " 27056,\n",
       " 92593,\n",
       " 18874,\n",
       " 35259,\n",
       " 10685,\n",
       " 10686,\n",
       " 27075,\n",
       " 76229,\n",
       " 27080,\n",
       " 92616,\n",
       " 51658,\n",
       " 10701,\n",
       " 10702,\n",
       " 43469,\n",
       " 43471,\n",
       " 18897,\n",
       " 92626,\n",
       " 92632,\n",
       " 59865,\n",
       " 84448,\n",
       " 18913,\n",
       " 43490,\n",
       " 51681,\n",
       " 92644,\n",
       " 59877,\n",
       " 27110,\n",
       " 84455,\n",
       " 27112,\n",
       " 35306,\n",
       " 68075,\n",
       " 92651,\n",
       " 59885,\n",
       " 51695,\n",
       " 27121,\n",
       " 92657,\n",
       " 59895,\n",
       " 68089,\n",
       " ...]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sku_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = training_set['output']\n",
    "training_set.drop(['output'], inplace = True, axis = 1)\n",
    "X_train = training_set[:]\n",
    "y_test = testing_set['output']\n",
    "testing_set.drop(['output'], inplace = True, axis = 1)\n",
    "X_test = testing_set[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ..., 12., 13.,  4.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization processing to speed-up calculation\n",
    "ss_X = StandardScaler()  \n",
    "ss_y = StandardScaler()  \n",
    "\n",
    "X_train_scaled = ss_X.fit_transform(X_train)  \n",
    "X_test_scaled = ss_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / (y_true + 0.0001)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1, please wait...\n",
      "Training on fold 1 completed\n",
      "Training on fold 2, please wait...\n",
      "Training on fold 2 completed\n",
      "Training on fold 3, please wait...\n",
      "Training on fold 3 completed\n",
      "Training on fold 4, please wait...\n",
      "Training on fold 4 completed\n",
      "Training on fold 5, please wait...\n",
      "Training on fold 5 completed\n",
      "The whole XGBoost takes 258.668119s!\n",
      "MSE Score:\n",
      "1367.7731198997715\n",
      "MAE Score:\n",
      "7.483407580563354\n",
      "MAPE Score:\n",
      "0.8860681060018148\n",
      "R^2 Score:\n",
      "0.4964251718515634\n"
     ]
    }
   ],
   "source": [
    "# Time series K-fold\n",
    "tscv = TimeSeriesSplit(n_splits = 5)\n",
    "mse_xgb_array = []\n",
    "mae_xgb_array = []\n",
    "mape_xgb_array = []\n",
    "r2_xgb_array = []\n",
    "startTime = time.time()\n",
    "fold = 0\n",
    "\n",
    "params = {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 4000, \n",
    "          'min_child_weight': 1, 'colsample_bytree': 0.6, \n",
    "          'subsample': 0.8, 'seed': 10}\n",
    "\n",
    "# Model training\n",
    "for train_index, val_index in tscv.split(X_train_scaled):\n",
    "    fold += 1\n",
    "    print('Training on fold %d, please wait...' % fold)\n",
    "    X_train_cv, X_val_cv, y_train_cv, y_val_cv = (X_train_scaled[train_index], X_train_scaled[val_index], \n",
    "                                                  y_train[train_index], y_train[val_index])\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train_cv, label = y_train_cv)\n",
    "    dval = xgb.DMatrix(X_val_cv)\n",
    "    model = xgb.train(params, dtrain, num_boost_round = 1000)\n",
    "    prediction = model.predict(dval)\n",
    "    \n",
    "    mse = mean_squared_error(prediction, y_val_cv)\n",
    "    mae = mean_absolute_error(prediction, y_val_cv)\n",
    "    mape = mean_absolute_percentage_error(prediction, y_val_cv)\n",
    "    r2 = r2_score(prediction, y_val_cv)\n",
    "    \n",
    "    mse_xgb_array.append(mse)\n",
    "    mae_xgb_array.append(mae)\n",
    "    mape_xgb_array.append(mape)\n",
    "    r2_xgb_array.append(r2)\n",
    "    \n",
    "    print('Training on fold %d completed' % fold)\n",
    "\n",
    "time_xgb = time.time() - startTime\n",
    "print('The whole XGBoost takes %fs!' % time_xgb, end = '\\n')\n",
    "\n",
    "mse_xgb = np.mean(mse_xgb_array)\n",
    "print('MSE Score:')  \n",
    "print(mse_xgb, end = '\\n')\n",
    "\n",
    "mae_xgb = np.mean(mae_xgb_array)\n",
    "print('MAE Score:')  \n",
    "print(mae_xgb, end = '\\n')\n",
    "\n",
    "mape_xgb = np.mean(mape_xgb_array)\n",
    "print('MAPE Score:')  \n",
    "print(mape_xgb, end = '\\n')\n",
    "\n",
    "r2_xgb = np.mean(r2_xgb_array)\n",
    "print('R^2 Score:')  \n",
    "print(r2_xgb, end = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost, please wait...\n",
      "Training on XGBoost completed\n",
      "The whole Quantile XGBoost takes 131.052861s!\n",
      "\n",
      "MSE Score:\n",
      "2136.314731211648\n",
      "MAE Score:\n",
      "11.350661437125106\n",
      "MAPE Score:\n",
      "0.7162362808166592\n",
      "R^2 Score:\n",
      "0.7705595921932032\n"
     ]
    }
   ],
   "source": [
    "params = {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 4000, \n",
    "          'min_child_weight': 1, 'colsample_bytree': 0.6, \n",
    "          'subsample': 0.8, 'seed': 10}\n",
    "\n",
    "startTime = time.time()\n",
    "\n",
    "# Model training\n",
    "print('Training XGBoost, please wait...')\n",
    "dtrain = xgb.DMatrix(X_train_scaled, label = y_train)\n",
    "dval = xgb.DMatrix(X_test_scaled)\n",
    "model = xgb.train(params, dtrain, num_boost_round = 1000)\n",
    "prediction_xgb = model.predict(dval)\n",
    "\n",
    "prediction_xgb = prediction_xgb * 0.8\n",
    "print('Training on XGBoost completed')\n",
    "\n",
    "mse_xgb = mean_squared_error(prediction_xgb, y_test)\n",
    "mae_xgb = mean_absolute_error(prediction_xgb, y_test)\n",
    "mape_xgb = mean_absolute_percentage_error(prediction_xgb, y_test)\n",
    "r2_xgb = r2_score(prediction_xgb, y_test)\n",
    "\n",
    "time_xgb = time.time() - startTime\n",
    "print('The whole Quantile XGBoost takes %fs!' % time_xgb)\n",
    "print()\n",
    "\n",
    "print('MSE Score:')  \n",
    "print(mse_xgb, end = '\\n')\n",
    "\n",
    "print('MAE Score:')  \n",
    "print(mae_xgb, end = '\\n')\n",
    "\n",
    "print('MAPE Score:')  \n",
    "print(mape_xgb, end = '\\n')\n",
    "\n",
    "print('R^2 Score:')  \n",
    "print(r2_xgb, end = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set = data[data['order_time'] == '2017/4/16']\n",
    "testing_set.index = testing_set['sku_id']\n",
    "testing_set_final = pd.concat((testing_set, y_test), axis = 1)\n",
    "testing_set_final['prediction_xgb'] = prediction_xgb\n",
    "testing_set_final['prediction_rf'] = prediction_rf\n",
    "testing_set_final['prediction_lgb'] = prediction_lgb\n",
    "testing_set_final['prediction_arima'] = prediction_arima\n",
    "testing_set_final.to_csv('/Users/mac/Desktop/UCB/290-Data-X/Project/Results/result.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The whole Quantile XGBoost takes 327.145439s!\n",
      "\n",
      "MSE Score:\n",
      "2141.9181131067844\n",
      "MAE Score:\n",
      "11.668476366679696\n",
      "MAPE Score:\n",
      "0.7411809333502455\n",
      "R^2 Score:\n",
      "0.785911063108908\n"
     ]
    }
   ],
   "source": [
    "prediction_all = prediction_rf * 0.5 + prediction_xgb * 0.4 + prediction_arima * 0.1\n",
    "mse_xgb = mean_squared_error(prediction_all, y_test)\n",
    "mae_xgb = mean_absolute_error(prediction_all, y_test)\n",
    "mape_xgb = mean_absolute_percentage_error(prediction_all, y_test)\n",
    "r2_xgb = r2_score(prediction_all, y_test)\n",
    "\n",
    "time_xgb = time.time() - startTime\n",
    "print('The whole Quantile XGBoost takes %fs!' % time_xgb)\n",
    "print()\n",
    "\n",
    "print('MSE Score:')  \n",
    "print(mse_xgb, end = '\\n')\n",
    "\n",
    "print('MAE Score:')  \n",
    "print(mae_xgb, end = '\\n')\n",
    "\n",
    "print('MAPE Score:')  \n",
    "print(mape_xgb, end = '\\n')\n",
    "\n",
    "print('R^2 Score:')  \n",
    "print(r2_xgb, end = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1, please wait...\n",
      "Training on fold 1 completed\n",
      "Training on fold 2, please wait...\n",
      "Training on fold 2 completed\n",
      "Training on fold 3, please wait...\n",
      "Training on fold 3 completed\n",
      "Training on fold 4, please wait...\n",
      "Training on fold 4 completed\n",
      "Training on fold 5, please wait...\n",
      "Training on fold 5 completed\n",
      "The whole Random Forest takes 222.537541s!\n",
      "MSE Score:\n",
      "1504.6800032107658\n",
      "MAE Score:\n",
      "7.444105386646619\n",
      "MAPE Score:\n",
      "0.9911027802408661\n",
      "R^2 Score:\n",
      "0.40914658573569157\n"
     ]
    }
   ],
   "source": [
    "# Time series K-fold\n",
    "tscv = TimeSeriesSplit(n_splits = 5)\n",
    "mse_rf_array = []\n",
    "mae_rf_array = []\n",
    "mape_rf_array = []\n",
    "r2_rf_array = []\n",
    "startTime = time.time()\n",
    "fold = 0\n",
    "\n",
    "# Model training\n",
    "for train_index, val_index in tscv.split(X_train_scaled):\n",
    "    fold += 1\n",
    "    print('Training on fold %d, please wait...' % fold)\n",
    "    X_train_cv, X_val_cv, y_train_cv, y_val_cv = (X_train_scaled[train_index], X_train_scaled[val_index], \n",
    "                                                  y_train[train_index], y_train[val_index])\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators = 600, max_depth = 13, min_samples_split = 3,\n",
    "                               min_samples_leaf = 10, oob_score = True, max_features = 'sqrt', \n",
    "                               random_state = 10)\n",
    "\n",
    "    rf.fit(X_train_cv, y_train_cv)\n",
    "    prediction = rf.predict(X_val_cv)\n",
    "    \n",
    "    mse = mean_squared_error(prediction, y_val_cv)\n",
    "    mae = mean_absolute_error(prediction, y_val_cv)\n",
    "    mape = mean_absolute_percentage_error(prediction, y_val_cv)\n",
    "    r2 = r2_score(prediction, y_val_cv)\n",
    "    \n",
    "    mse_rf_array.append(mse)\n",
    "    mae_rf_array.append(mae)\n",
    "    mape_rf_array.append(mape)\n",
    "    r2_rf_array.append(r2)\n",
    "    \n",
    "    print('Training on fold %d completed' % fold)\n",
    "\n",
    "time_rf = time.time() - startTime\n",
    "print('The whole Random Forest takes %fs!' % time_rf, end = '\\n')\n",
    "\n",
    "mse_rf = np.mean(mse_rf_array)\n",
    "print('MSE Score:')  \n",
    "print(mse_rf, end = '\\n')\n",
    "\n",
    "mae_rf = np.mean(mae_rf_array)\n",
    "print('MAE Score:')  \n",
    "print(mae_rf, end = '\\n')\n",
    "\n",
    "mape_rf = np.mean(mape_rf_array)\n",
    "print('MAPE Score:')  \n",
    "print(mape_rf, end = '\\n')\n",
    "\n",
    "r2_rf = np.mean(r2_rf_array)\n",
    "print('R^2 Score:')  \n",
    "print(r2_rf, end = '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest, please wait...\n",
      "Training on Random Forest completed\n",
      "The whole Random Forest takes 153.967965s!\n",
      "\n",
      "MSE Score:\n",
      "2066.323610053949\n",
      "MAE Score:\n",
      "12.249568982063353\n",
      "MAPE Score:\n",
      "0.7611420514018358\n",
      "R^2 Score:\n",
      "0.7917750627800018\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "\n",
    "# Model training\n",
    "print('Training Random Forest, please wait...')\n",
    "rf = RandomForestRegressor(n_estimators = 1000, max_depth = 13, min_samples_split = 3,\n",
    "                           min_samples_leaf = 10, oob_score = True, max_features = 'sqrt', \n",
    "                           random_state = 10)\n",
    "\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "prediction_rf = rf.predict(X_test_scaled)\n",
    "\n",
    "print('Training on Random Forest completed')\n",
    "\n",
    "mse_rf = mean_squared_error(prediction_rf, y_test)\n",
    "mae_rf = mean_absolute_error(prediction_rf, y_test)\n",
    "mape_rf = mean_absolute_percentage_error(prediction_rf, y_test)\n",
    "r2_rf = r2_score(prediction_rf, y_test)\n",
    "\n",
    "time_rf = time.time() - startTime\n",
    "print('The whole Random Forest takes %fs!' % time_rf)\n",
    "print()\n",
    "\n",
    "print('MSE Score:')  \n",
    "print(mse_rf, end = '\\n')\n",
    "\n",
    "print('MAE Score:')  \n",
    "print(mae_rf, end = '\\n')\n",
    "\n",
    "print('MAPE Score:')  \n",
    "print(mape_rf, end = '\\n')\n",
    "\n",
    "print('R^2 Score:')  \n",
    "print(r2_rf, end = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1, please wait...\n",
      "Training on fold 1 completed\n",
      "Training on fold 2, please wait...\n",
      "Training on fold 2 completed\n",
      "Training on fold 3, please wait...\n",
      "Training on fold 3 completed\n",
      "Training on fold 4, please wait...\n",
      "Training on fold 4 completed\n",
      "Training on fold 5, please wait...\n",
      "Training on fold 5 completed\n",
      "The whole LightGBM takes 217.695097s!\n",
      "MSE Score:\n",
      "1746.689439498652\n",
      "MAE Score:\n",
      "7.924171892545134\n",
      "MAPE Score:\n",
      "3.2718696167649517\n",
      "R^2 Score:\n",
      "0.4510815537830883\n"
     ]
    }
   ],
   "source": [
    "# Time series K-fold\n",
    "tscv = TimeSeriesSplit(n_splits = 5)\n",
    "mse_lgb_array = []\n",
    "mae_lgb_array = []\n",
    "mape_lgb_array = []\n",
    "r2_lgb_array = []\n",
    "startTime = time.time()\n",
    "fold = 0\n",
    "\n",
    "# Model training\n",
    "for train_index, val_index in tscv.split(X_train_scaled):\n",
    "    fold += 1\n",
    "    print('Training on fold %d, please wait...' % fold)\n",
    "    X_train_cv, X_val_cv, y_train_cv, y_val_cv = (X_train_scaled[train_index], X_train_scaled[val_index], \n",
    "                                                  y_train[train_index], y_train[val_index])\n",
    "    \n",
    "    lgb_params = {'n_estimators': 4000, 'max_depth': 8, 'min_data_in_leaf': 10, \n",
    "                  'subsample': 0.9, 'learning_rate': 0.1, 'colsample_bytree': 0.9, \n",
    "                  'boosting_type': 'gbdt', 'random_state': 10}\n",
    "    model = lgb.LGBMRegressor(objective = 'regression', **lgb_params)\n",
    "    model.fit(X_train_cv, y_train_cv)\n",
    "    prediction = model.predict(X_val_cv)\n",
    "\n",
    "    mse = mean_squared_error(prediction, y_val_cv)\n",
    "    mae = mean_absolute_error(prediction, y_val_cv)\n",
    "    mape = mean_absolute_percentage_error(prediction, y_val_cv)\n",
    "    r2 = r2_score(prediction, y_val_cv)\n",
    "    \n",
    "    mse_lgb_array.append(mse)\n",
    "    mae_lgb_array.append(mae)\n",
    "    mape_lgb_array.append(mape)\n",
    "    r2_lgb_array.append(r2)\n",
    "    \n",
    "    print('Training on fold %d completed' % fold)\n",
    "\n",
    "time_lgb = time.time() - startTime\n",
    "print('The whole LightGBM takes %fs!' % time_lgb, end = '\\n')\n",
    "\n",
    "mse_lgb = np.mean(mse_lgb_array)\n",
    "print('MSE Score:')  \n",
    "print(mse_lgb, end = '\\n')\n",
    "\n",
    "mae_lgb = np.mean(mae_lgb_array)\n",
    "print('MAE Score:')  \n",
    "print(mae_lgb, end = '\\n')\n",
    "\n",
    "mape_lgb = np.mean(mape_lgb_array)\n",
    "print('MAPE Score:')  \n",
    "print(mape_lgb, end = '\\n')\n",
    "\n",
    "r2_lgb = np.mean(r2_lgb_array)\n",
    "print('R^2 Score:')  \n",
    "print(r2_lgb, end = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LightGBM, please wait...\n",
      "Training on LightGBM completed\n",
      "The whole LightGBM takes 45.779983s!\n",
      "\n",
      "MSE Score:\n",
      "3315.496774028581\n",
      "MAE Score:\n",
      "16.798301303247364\n",
      "MAPE Score:\n",
      "21.032191139890923\n",
      "R^2 Score:\n",
      "0.7447772452999813\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "\n",
    "# Model training\n",
    "print('Training LightGBM, please wait...')\n",
    "lgb_params = {'n_estimators': 4000, 'max_depth': 8, 'min_data_in_leaf': 10, \n",
    "              'subsample': 0.9, 'learning_rate': 0.1, 'colsample_bytree': 0.9, \n",
    "              'boosting_type': 'gbdt', 'random_state': 10}\n",
    "model = lgb.LGBMRegressor(objective = 'regression', **lgb_params)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "prediction_lgb = model.predict(X_test_scaled)\n",
    "\n",
    "print('Training on LightGBM completed')\n",
    "\n",
    "mse_lgb = mean_squared_error(prediction_lgb, y_test)\n",
    "mae_lgb = mean_absolute_error(prediction_lgb, y_test)\n",
    "mape_lgb = mean_absolute_percentage_error(prediction_lgb, y_test)\n",
    "r2_lgb = r2_score(prediction_lgb, y_test)\n",
    "\n",
    "time_lgb = time.time() - startTime\n",
    "print('The whole LightGBM takes %fs!' % time_lgb)\n",
    "print()\n",
    "\n",
    "print('MSE Score:')  \n",
    "print(mse_lgb, end = '\\n')\n",
    "\n",
    "print('MAE Score:')  \n",
    "print(mae_lgb, end = '\\n')\n",
    "\n",
    "print('MAPE Score:')  \n",
    "print(mape_lgb, end = '\\n')\n",
    "\n",
    "print('R^2 Score:')  \n",
    "print(r2_lgb, end = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "from pandas.plotting import autocorrelation_plot\n",
    "from matplotlib import pyplot\n",
    "\n",
    "%matplotlib\n",
    "y_train_tmp = list(y_train.loc[16385])\n",
    "autocorrelation_plot(y_train_tmp)\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ARIMA, please wait...\n",
      "Training on ARIMA completed\n",
      "The whole ARIMA takes 86.671394s!\n",
      "\n",
      "MSE Score:\n",
      "4392.380654143197\n",
      "MAE Score:\n",
      "13.457189962564083\n",
      "MAPE Score:\n",
      "3098.2397103551652\n",
      "R^2 Score:\n",
      "0.7076162344679846\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "\n",
    "# Model training\n",
    "print('Training ARIMA, please wait...')\n",
    "\n",
    "prediction_arima = []\n",
    "y_train_tmp = list(y_train)\n",
    "\n",
    "prediction_df = pd.DataFrame([], index = y_test.index, columns = ['prediction'])\n",
    "\n",
    "for sku in sku_id:\n",
    "    y_train_tmp = list(y_train.loc[sku])\n",
    "    #print(y_train_tmp)\n",
    "    #print(len(y_train_tmp))\n",
    "    model = SARIMAX(y_train_tmp)\n",
    "    model_fit = model.fit()\n",
    "    prediction = model_fit.predict(start = len(y_train_tmp), end = len(y_train_tmp))\n",
    "    prediction_df['prediction'].loc[sku] = prediction[0]\n",
    "    \n",
    "prediction_arima = np.reshape(prediction_df.values, y_test.values.shape, )\n",
    "print('Training on ARIMA completed')\n",
    "\n",
    "mse_arima = mean_squared_error(prediction_arima, y_test)\n",
    "mae_arima = mean_absolute_error(prediction_arima, y_test)\n",
    "mape_arima = mean_absolute_percentage_error(prediction_arima, y_test.values)\n",
    "r2_arima = r2_score(prediction_arima, y_test)\n",
    "\n",
    "time_arima = time.time() - startTime\n",
    "print('The whole ARIMA takes %fs!' % time_arima)\n",
    "print()\n",
    "\n",
    "print('MSE Score:')  \n",
    "print(mse_arima, end = '\\n')\n",
    "\n",
    "print('MAE Score:')  \n",
    "print(mae_arima, end = '\\n')\n",
    "\n",
    "print('MAPE Score:')  \n",
    "print(mape_arima, end = '\\n')\n",
    "\n",
    "print('R^2 Score:')  \n",
    "print(r2_arima, end = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Tony)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
